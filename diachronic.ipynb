{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import TreebankWordTokenizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec needs list of lists, so I'm going to open 2 files\n",
    "\n",
    "with open(\"/home/josh/Documents/a-library-nlp-project/theanarchistlibrary.org/library/zvonimir-kontrec-architecture-is-a-political-act.html\", \"r\") as file:\n",
    "    html = file.read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "with open(\"/home/josh/Documents/a-library-nlp-project/theanarchistlibrary.org/library/zundlumpen-will-o-the-wisps.html\", \"r\") as file:\n",
    "    html2 = file.read()\n",
    "soup2 = BeautifulSoup(html2, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert html to text\n",
    "first_small_doc = soup.get_text()\n",
    "second_small_doc = soup2.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_small_doc\n",
    "#print(first_small_doc)\n",
    "#print(second_small_doc)\n",
    "\n",
    "#calling it by itself shows a bunch of line breaks and formatting junk\n",
    "#printing it makes it all nice and pretty and readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = []\n",
    "docs.append(first_small_doc)\n",
    "docs.append(second_small_doc)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "docs_tokenized = []\n",
    "for doc in docs:\n",
    "    docs_tokenized.append(tokenizer.tokenize(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(docs_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build skipgram model\n",
    "model_sg = Word2Vec(sentences=docs_tokenized, window=5, min_count=3, workers=4, epochs=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('for', 0.9980694651603699),\n",
       " ('this', 0.9979365468025208),\n",
       " ('In', 0.9979010820388794),\n",
       " ('system', 0.9978348016738892),\n",
       " ('way', 0.9978195428848267),\n",
       " ('in', 0.9977800846099854),\n",
       " ('their', 0.9977703094482422),\n",
       " ('towards', 0.9977662563323975),\n",
       " ('building', 0.9977622032165527),\n",
       " ('after', 0.9977437257766724)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.most_similar('the', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build CBOW model\n",
    "model_cbow = Word2Vec(sentences=docs_tokenized, window=5, min_count=3, workers=4, epochs=5, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('through', 0.9726642370223999),\n",
       " ('into', 0.9719277024269104),\n",
       " (\"n't\", 0.9718241691589355),\n",
       " ('was', 0.9717423915863037),\n",
       " ('also', 0.9716292023658752),\n",
       " (')', 0.9716008305549622),\n",
       " ('it', 0.971388041973114),\n",
       " ('I', 0.9713448286056519),\n",
       " ('(', 0.9712851047515869),\n",
       " ('is', 0.9712598919868469)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow.wv.most_similar('media', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok, now let's do it for a few more docs and compare cosine cimilarity between two models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 0.9982710480690002),\n",
       " ('ideas', 0.9982483386993408),\n",
       " ('left', 0.9982380867004395),\n",
       " ('many', 0.9981945157051086),\n",
       " ('by', 0.9981881380081177),\n",
       " ('to', 0.9981729984283447),\n",
       " (',', 0.9981165528297424),\n",
       " ('as', 0.998098611831665),\n",
       " ('on', 0.9980598092079163),\n",
       " ('radical', 0.9980372786521912)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"/home/josh/Documents/a-library-nlp-project/theanarchistlibrary.org/library/zundlumpen-radical-left-i-m-breaking-up-with-you.html\", \"r\") as file:\n",
    "    html3 = file.read()\n",
    "soup3 = BeautifulSoup(html3, \"html.parser\")\n",
    "with open(\"/home/josh/Documents/a-library-nlp-project/theanarchistlibrary.org/library/zosia-brom-insert-topic-of-the-day-has-divided-anarchists.html\", \"r\") as file:\n",
    "    html4 = file.read()\n",
    "soup4 = BeautifulSoup(html4, \"html.parser\")\n",
    "\n",
    "#convert html to text\n",
    "third_small_doc = soup3.get_text()\n",
    "fourth_small_doc = soup4.get_text()\n",
    "\n",
    "#this could be decade folders when i build this out\n",
    "docs_next_corpus = []\n",
    "docs_next_corpus.append(third_small_doc)\n",
    "docs_next_corpus.append(fourth_small_doc)\n",
    "len(docs_next_corpus)\n",
    "\n",
    "docs_next_tokenized = []\n",
    "for doc in docs_next_corpus:\n",
    "    docs_next_tokenized.append(tokenizer.tokenize(doc))\n",
    "\n",
    "model_sg_next = Word2Vec(sentences=docs_next_tokenized, window=5, min_count=3, workers=4, epochs=5, sg=1)\n",
    "model_sg_next.wv.most_similar('the', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.9978370070457458),\n",
       " ('many', 0.9977409243583679),\n",
       " ('a', 0.997643232345581),\n",
       " ('that', 0.9976242780685425),\n",
       " ('but', 0.9976202845573425),\n",
       " ('we', 0.997607409954071),\n",
       " ('or', 0.9975824356079102),\n",
       " ('by', 0.9975618124008179),\n",
       " ('communist', 0.9975566864013672),\n",
       " ('from', 0.9975111484527588)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding a word that is in both doc lists to see top 10 most similar words\n",
    "model_sg_next.wv.most_similar('political', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('backwards', 0.9973574280738831),\n",
       " ('anti-civilizational', 0.9973565936088562),\n",
       " ('thought', 0.9972497224807739),\n",
       " ('were', 0.9972323179244995),\n",
       " ('life', 0.9972214698791504),\n",
       " ('In', 0.9971413016319275),\n",
       " ('Instead', 0.997123122215271),\n",
       " ('within', 0.9971001148223877),\n",
       " ('so', 0.9970480799674988),\n",
       " ('it', 0.9970154166221619)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.most_similar('political', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the vectors for the same words in different corpora\n",
    "vector_pol_1 = model_sg.wv['political']\n",
    "vector_pol_2 = model_sg_next.wv['political']\n",
    "\n",
    "vector_the_1 = model_sg.wv['the']\n",
    "vector_the_2 = model_sg_next.wv['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check structure of vector\n",
    "#vector_pol_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(vector):\n",
    "    res = vector.reshape(1, -1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_pol_1 = reshape(vector_pol_1)\n",
    "vector_pol_2 = reshape(vector_pol_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7454266]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vector_pol_1, vector_pol_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_the_1 = reshape(vector_the_1)\n",
    "vector_the_2 = reshape(vector_the_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7461838]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vector_the_1, vector_the_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9966311]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vector_the_1, vector_pol_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99663097"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.similarity(\"the\", \"political\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
